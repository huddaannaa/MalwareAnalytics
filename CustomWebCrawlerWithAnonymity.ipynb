{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-] Establishing TOR routing ...\n",
      "[-] Done!\n",
      " \n",
      "____\n",
      "[-] Passing normal traffic through TOR network \n",
      "[-] Unable to pass trafic ...\n",
      "____\n",
      "[-] Tor connection established\n",
      " \n",
      "[-] Original IP:  41.189.179.24\n",
      "[+] New IP     :  41.189.179.24\n",
      " \n",
      "[+]  35  http or https links\n",
      "\n",
      "__________\n",
      "CNNMoney - Business, financial and personal finance news\n",
      "http://money.cnn.com/INTERNATIONAL/\n",
      "__________\n",
      "CNNMoney - Business, financial and personal finance news\n",
      "http://money.cnn.com/INTERNATIONAL/\n",
      "__________\n",
      "Business News and Financial News - CNNMoney\n",
      "http://money.cnn.com/news/\n",
      "__________\n",
      "Luxury - CNNMoney\n",
      "http://money.cnn.com/luxury/\n",
      "__________\n",
      "Media - CNN Media\n",
      "http://money.cnn.com/media\n",
      "__________\n",
      "CNN International - Home | Facebook\n",
      "https://www.facebook.com/cnninternational\n",
      "__________\n",
      "CNN International (@cnni) | Twitter\n",
      "https://twitter.com/cnni\n",
      "__________\n",
      "\n",
      "CNN (@cnn) â€¢ Instagram photos and videos\n",
      "\n",
      "https://instagram.com/cnn\n",
      "__________\n",
      "CNNMoney - Business, financial and personal finance news\n",
      "http://money.cnn.com/INTERNATIONAL/\n",
      "__________\n",
      "Business News and Financial News - CNNMoney\n",
      "http://money.cnn.com/news/\n",
      "__________\n",
      "Luxury - CNNMoney\n",
      "http://money.cnn.com/luxury/\n",
      "__________\n",
      "Media - CNN Media\n",
      "http://money.cnn.com/media\n",
      "\n",
      "[+]  12  http or https links on  Trump ...\n",
      "\n",
      "[+] Done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"LIBRARIES\"\"\"\n",
    "\n",
    "import urllib, urllib2, requests, os, socks\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\"\"\"FUNCTIONS\"\"\"\n",
    "\n",
    "def checkIP():\n",
    "    return requests.get('http://ip.42.pl/raw').text\n",
    "original_IP = checkIP()\n",
    "\n",
    "def myTor():\n",
    "    try:\n",
    "        print '[-] Establishing TOR routing ...'\n",
    "        socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS5, \"127.0.0.1\", 9050, True)\n",
    "        print '[-] Done!'\n",
    "        print ' '\n",
    "    except:\n",
    "        print '[-] Unable to establish TOR routing ...'\n",
    "        #sys.close()\n",
    "    print '____'\n",
    "    try:\n",
    "        print '[-] Passing normal traffic through TOR network '\n",
    "        socket.socket = socks.socksocket\n",
    "        print '[-] Done!'\n",
    "    except:\n",
    "        print '[-] Unable to pass trafic ...'\n",
    "        #sys.close()\n",
    "    print '____'\n",
    "    print '[-] Tor connection established'   \n",
    "\n",
    "def email_extract(string):\n",
    "    import re\n",
    "    sp = re.split(r'\\s|,', string)\n",
    "    return [re.match(r'\\w*@\\w*.\\w*.\\w*', sp[n]).group() for n in range(len(sp))]\n",
    "\n",
    "def Extract_http_s(url):\n",
    "    soup = BeautifulSoup(requests.get(url).text, 'lxml')\n",
    "    res, lnks = [], [link.get('href') for link in soup.find_all('a')]\n",
    "    for n in range(len(lnks)):\n",
    "        if ('http' in str(lnks[n])) or ('https' in str(lnks[n])):\n",
    "            try: res.append(lnks[n])\n",
    "            except: print '[+] HTTP Error 522: Origin Connection Time-out'\n",
    "        else: pass\n",
    "    return res\n",
    "\n",
    "def open_url(lnks2, word):\n",
    "    data1, ans = urllib2.urlopen(lnks2).read().split(), []\n",
    "    for n2 in data1:\n",
    "        if (word in n2) or (word == n2) or (word == n2.lower()) or (word == n2.lower()) or (word[0].upper() + word[1:].lower() == n2): ans.append(n)\n",
    "        else: pass\n",
    "    if len(ans) == 0: return False\n",
    "    else: return True   \n",
    "    \n",
    "def crawl_title(url):\n",
    "    print BeautifulSoup(urllib2.urlopen(url), 'lxml').title.string\n",
    "\n",
    "\"\"\" MAIN \"\"\"\n",
    "\"\"\" parameters \"\"\"\n",
    "\n",
    "links= ['http://edition.cnn.com/']\n",
    "\n",
    "myTor()\n",
    "print ' '\n",
    "print '[-] Original IP: ', original_IP\n",
    "print '[+] New IP     : ', checkIP()\n",
    "print ' '\n",
    "#link_bank = open('/home/hud/Desktop/link_pages', 'r').readlines()\n",
    "word  = 'Trump'\n",
    "\n",
    "\"\"\"function calls\"\"\"\n",
    "cnt, all_http_s = [], [Extract_http_s(pages) for pages in links][0]\n",
    "print '[+] ', len(all_http_s), ' http or https links'\n",
    "print ''\n",
    "\n",
    "for n in range(len(all_http_s)):\n",
    "    try:\n",
    "        conn = open_url(all_http_s[n], word)\n",
    "        if conn == True:\n",
    "            print '__________'\n",
    "            crawl_title(all_http_s[n])\n",
    "            print all_http_s[n]\n",
    "            cnt.append(all_http_s[n])\n",
    "        else: pass\n",
    "    except: pass\n",
    "    \n",
    "print ''\n",
    "print '[+] ', len(cnt), ' http or https links on ', word, '...'\n",
    "print ''\n",
    "print '[+] Done!'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
